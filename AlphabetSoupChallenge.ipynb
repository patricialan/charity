{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv(\"charity_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.429900e+04</td>\n",
       "      <td>34299.000000</td>\n",
       "      <td>3.429900e+04</td>\n",
       "      <td>34299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.191852e+08</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>2.769199e+06</td>\n",
       "      <td>0.532406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.451472e+08</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>8.713045e+07</td>\n",
       "      <td>0.498956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.052060e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.748482e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.656317e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.526117e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.742000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.960869e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.597806e+09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                EIN        STATUS       ASK_AMT  IS_SUCCESSFUL\n",
       "count  3.429900e+04  34299.000000  3.429900e+04   34299.000000\n",
       "mean   5.191852e+08      0.999854  2.769199e+06       0.532406\n",
       "std    2.451472e+08      0.012073  8.713045e+07       0.498956\n",
       "min    1.052060e+07      0.000000  5.000000e+03       0.000000\n",
       "25%    2.748482e+08      1.000000  5.000000e+03       0.000000\n",
       "50%    4.656317e+08      1.000000  5.000000e+03       1.000000\n",
       "75%    7.526117e+08      1.000000  7.742000e+03       1.000000\n",
       "max    9.960869e+08      1.000000  8.597806e+09       1.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of rows (34,299)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>205559542</td>\n",
       "      <td>INTERNATIONAL FEDERATION OF FLY FISHERS INC</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>CommunityServ</td>\n",
       "      <td>Trust</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>205918776</td>\n",
       "      <td>THE STEWART FOUNDATION INC</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>0</td>\n",
       "      <td>25000-99999</td>\n",
       "      <td>Y</td>\n",
       "      <td>7287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10155</th>\n",
       "      <td>330970564</td>\n",
       "      <td>META POINT INC</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>0</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20518</th>\n",
       "      <td>510594485</td>\n",
       "      <td>MOMS CLUB</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2100</td>\n",
       "      <td>CommunityServ</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>841164329</td>\n",
       "      <td>SKYVIEW VILLAGE INC SENIOR HOUSING</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             EIN                                         NAME  \\\n",
       "2816   205559542  INTERNATIONAL FEDERATION OF FLY FISHERS INC   \n",
       "2928   205918776                   THE STEWART FOUNDATION INC   \n",
       "10155  330970564                               META POINT INC   \n",
       "20518  510594485                                    MOMS CLUB   \n",
       "29590  841164329           SKYVIEW VILLAGE INC SENIOR HOUSING   \n",
       "\n",
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION       USE_CASE  \\\n",
       "2816                T3  CompanySponsored          C2000  CommunityServ   \n",
       "2928                T3       Independent          C1000   Preservation   \n",
       "10155               T3       Independent          C1000   Preservation   \n",
       "20518               T3  CompanySponsored          C2100  CommunityServ   \n",
       "29590               T3       Independent          C1000   Preservation   \n",
       "\n",
       "      ORGANIZATION  STATUS   INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "2816         Trust       0            0                      N     5000   \n",
       "2928         Trust       0  25000-99999                      Y     7287   \n",
       "10155        Trust       0  10000-24999                      N     5000   \n",
       "20518  Association       0            0                      N     5000   \n",
       "29590  Association       0            0                      N     5000   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "2816               1  \n",
       "2928               1  \n",
       "10155              1  \n",
       "20518              0  \n",
       "29590              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many unique values in \"STATUS\"\n",
    "display(df['STATUS'].unique())\n",
    "\n",
    "# see how many rows have \"0\" for STATUS\n",
    "df[df['STATUS'] == 0]\n",
    "# answer: 5 (of 34,299 total rows)\n",
    "# conclusion: drop status column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0   Association              0                      N     5000              1  \n",
       "1  Co-operative         1-9999                      N   108590              1  \n",
       "2   Association              0                      N     5000              0  \n",
       "3         Trust    10000-24999                      N     6692              1  \n",
       "4         Trust  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove id columns (b/c not associated with outcome of using money effectively); also remove status\n",
    "df.drop(columns=['EIN','NAME','STATUS'], inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    34272\n",
       "Y       27\n",
       "Name: SPECIAL_CONSIDERATIONS, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see count of unique values for \"special_considerations\"\n",
    "df['SPECIAL_CONSIDERATIONS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE          17\n",
       "AFFILIATION                6\n",
       "CLASSIFICATION            71\n",
       "USE_CASE                   5\n",
       "ORGANIZATION               4\n",
       "INCOME_AMT                 9\n",
       "SPECIAL_CONSIDERATIONS     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see number of unique values per column (do we need to bucket?)\n",
    "\n",
    "# generate categorical variable list\n",
    "df_cat = df.dtypes[df.dtypes == 'object'].index.tolist()\n",
    "\n",
    "# check the number of unique values in each column\n",
    "df[df_cat].nunique()\n",
    "\n",
    "# answer: check out \"application_type\" & \"classification\" (b/c > 10 unique values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# application_type: check out unique values\n",
    "applicationType_counts = df['APPLICATION_TYPE'].value_counts()\n",
    "applicationType_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# density plot to visualize counts\n",
    "applicationType_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2500.0, 5000.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# zoom in\n",
    "applicationType_counts.plot.density()\n",
    "plt.xlim(left=-2500,right=5000)\n",
    "\n",
    "# note: no binning threshold to be derived from density plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "T9         156\n",
       "Other      120\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# application_type: bin types with < 100 counts in \"other\" (so that I have 10 categories in total)\n",
    "\n",
    "replace_appType = list(applicationType_counts[applicationType_counts < 100].index)\n",
    "\n",
    "# replace in df\n",
    "for appType in replace_appType:\n",
    "    df.APPLICATION_TYPE = df.APPLICATION_TYPE.replace(appType, \"Other\")\n",
    "    \n",
    "# ensure binning was successful\n",
    "df.APPLICATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C6000       15\n",
       "C1800       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1278       10\n",
       "C1238       10\n",
       "C1237        9\n",
       "C1235        9\n",
       "C7210        7\n",
       "C1720        6\n",
       "C4100        6\n",
       "C2400        6\n",
       "C1600        5\n",
       "C1257        5\n",
       "C1260        3\n",
       "C0           3\n",
       "C2710        3\n",
       "C1267        2\n",
       "C1246        2\n",
       "C1256        2\n",
       "C3200        2\n",
       "C1234        2\n",
       "C1732        1\n",
       "C6100        1\n",
       "C4500        1\n",
       "C2150        1\n",
       "C1248        1\n",
       "C2570        1\n",
       "C2561        1\n",
       "C4200        1\n",
       "C8210        1\n",
       "C1283        1\n",
       "C2600        1\n",
       "C1236        1\n",
       "C2190        1\n",
       "C4120        1\n",
       "C2170        1\n",
       "C1900        1\n",
       "C2380        1\n",
       "C5200        1\n",
       "C1245        1\n",
       "C1370        1\n",
       "C2500        1\n",
       "C1820        1\n",
       "C1580        1\n",
       "C3700        1\n",
       "C1570        1\n",
       "C1728        1\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classification: check out unique values\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "classification_counts = df['CLASSIFICATION'].value_counts()\n",
    "classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-10394.0, 20000.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# density plot to visualize counts\n",
    "classification_counts.plot.density()\n",
    "plt.xlim(right=20000)\n",
    "\n",
    "# note: also no binning threshold to be derived from density plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Other      887\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# application_type: bin types with < 100 counts in \"other\" (so that I have 10 categories in total)\n",
    "\n",
    "replace_classification = list(classification_counts[classification_counts < 115].index)\n",
    "\n",
    "# replace in df\n",
    "for classification in replace_classification:\n",
    "    df.CLASSIFICATION = df.CLASSIFICATION.replace(classification, \"Other\")\n",
    "    \n",
    "# ensure binning was successful\n",
    "df.CLASSIFICATION.value_counts()\n",
    "\n",
    "# note: kept 10 categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check value counts of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column\n",
      "T3       27037\n",
      "T4        1542\n",
      "T6        1216\n",
      "T5        1173\n",
      "T19       1065\n",
      "T8         737\n",
      "T7         725\n",
      "T10        528\n",
      "T9         156\n",
      "Other      120\n",
      "Name: APPLICATION_TYPE, dtype: int64\n",
      "-------------\n",
      "column\n",
      "Independent         18480\n",
      "CompanySponsored    15705\n",
      "Family/Parent          64\n",
      "National               33\n",
      "Regional               13\n",
      "Other                   4\n",
      "Name: AFFILIATION, dtype: int64\n",
      "-------------\n",
      "column\n",
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "Other      887\n",
      "C7000      777\n",
      "C1700      287\n",
      "C4000      194\n",
      "C5000      116\n",
      "Name: CLASSIFICATION, dtype: int64\n",
      "-------------\n",
      "column\n",
      "Preservation     28095\n",
      "ProductDev        5671\n",
      "CommunityServ      384\n",
      "Heathcare          146\n",
      "Other                3\n",
      "Name: USE_CASE, dtype: int64\n",
      "-------------\n",
      "column\n",
      "Trust           23515\n",
      "Association     10255\n",
      "Co-operative      486\n",
      "Corporation        43\n",
      "Name: ORGANIZATION, dtype: int64\n",
      "-------------\n",
      "column\n",
      "0                24388\n",
      "25000-99999       3747\n",
      "100000-499999     3374\n",
      "1M-5M              955\n",
      "1-9999             728\n",
      "10000-24999        543\n",
      "10M-50M            240\n",
      "5M-10M             185\n",
      "50M+               139\n",
      "Name: INCOME_AMT, dtype: int64\n",
      "-------------\n",
      "column\n",
      "N    34272\n",
      "Y       27\n",
      "Name: SPECIAL_CONSIDERATIONS, dtype: int64\n",
      "-------------\n",
      "column\n",
      "5000       25398\n",
      "10478          3\n",
      "15583          3\n",
      "6725           3\n",
      "63981          3\n",
      "           ...  \n",
      "772556         1\n",
      "70103          1\n",
      "27096          1\n",
      "25049          1\n",
      "1138700        1\n",
      "Name: ASK_AMT, Length: 8747, dtype: int64\n",
      "-------------\n",
      "column\n",
      "1    18261\n",
      "0    16038\n",
      "Name: IS_SUCCESSFUL, dtype: int64\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "columns_list = list(df.columns)\n",
    "columns_list\n",
    "\n",
    "for column in columns_list:\n",
    "    print(\"column\")\n",
    "    print(df[column].value_counts())\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "      <th>APPLICATION_TYPE_T9</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  \\\n",
       "0                     0.0                   1.0                   0.0   \n",
       "1                     0.0                   0.0                   0.0   \n",
       "2                     0.0                   0.0                   0.0   \n",
       "3                     0.0                   0.0                   0.0   \n",
       "4                     0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  1.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  1.0   \n",
       "3                  1.0                  0.0                  0.0   \n",
       "4                  1.0                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T9  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0                  0.0  ...                0.0                     0.0   \n",
       "1                  0.0  ...                1.0                     0.0   \n",
       "2                  0.0  ...                0.0                     0.0   \n",
       "3                  0.0  ...                0.0                     1.0   \n",
       "4                  0.0  ...                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                     0.0              0.0                0.0   \n",
       "1                     0.0              0.0                0.0   \n",
       "2                     0.0              0.0                0.0   \n",
       "3                     0.0              0.0                0.0   \n",
       "4                     0.0              0.0                0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       1.0                       0.0  \n",
       "1                       1.0                       0.0  \n",
       "2                       1.0                       0.0  \n",
       "3                       1.0                       0.0  \n",
       "4                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df[df_cat]))\n",
    "\n",
    "# add the encoded variable names to the DataFrame\n",
    "encode_df.columns = enc.get_feature_names(df_cat)\n",
    "display(encode_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  \\\n",
       "0     5000              1                     0.0                   1.0   \n",
       "1   108590              1                     0.0                   0.0   \n",
       "2     5000              0                     0.0                   0.0   \n",
       "3     6692              1                     0.0                   0.0   \n",
       "4   142590              1                     0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                   0.0                  0.0                  0.0   \n",
       "1                   0.0                  1.0                  0.0   \n",
       "2                   0.0                  0.0                  0.0   \n",
       "3                   0.0                  1.0                  0.0   \n",
       "4                   0.0                  1.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  1.0                  0.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['ASK_AMT',\n",
       " 'IS_SUCCESSFUL',\n",
       " 'APPLICATION_TYPE_Other',\n",
       " 'APPLICATION_TYPE_T10',\n",
       " 'APPLICATION_TYPE_T19',\n",
       " 'APPLICATION_TYPE_T3',\n",
       " 'APPLICATION_TYPE_T4',\n",
       " 'APPLICATION_TYPE_T5',\n",
       " 'APPLICATION_TYPE_T6',\n",
       " 'APPLICATION_TYPE_T7',\n",
       " 'APPLICATION_TYPE_T8',\n",
       " 'APPLICATION_TYPE_T9',\n",
       " 'AFFILIATION_CompanySponsored',\n",
       " 'AFFILIATION_Family/Parent',\n",
       " 'AFFILIATION_Independent',\n",
       " 'AFFILIATION_National',\n",
       " 'AFFILIATION_Other',\n",
       " 'AFFILIATION_Regional',\n",
       " 'CLASSIFICATION_C1000',\n",
       " 'CLASSIFICATION_C1200',\n",
       " 'CLASSIFICATION_C1700',\n",
       " 'CLASSIFICATION_C2000',\n",
       " 'CLASSIFICATION_C2100',\n",
       " 'CLASSIFICATION_C3000',\n",
       " 'CLASSIFICATION_C4000',\n",
       " 'CLASSIFICATION_C5000',\n",
       " 'CLASSIFICATION_C7000',\n",
       " 'CLASSIFICATION_Other',\n",
       " 'USE_CASE_CommunityServ',\n",
       " 'USE_CASE_Heathcare',\n",
       " 'USE_CASE_Other',\n",
       " 'USE_CASE_Preservation',\n",
       " 'USE_CASE_ProductDev',\n",
       " 'ORGANIZATION_Association',\n",
       " 'ORGANIZATION_Co-operative',\n",
       " 'ORGANIZATION_Corporation',\n",
       " 'ORGANIZATION_Trust',\n",
       " 'INCOME_AMT_0',\n",
       " 'INCOME_AMT_1-9999',\n",
       " 'INCOME_AMT_10000-24999',\n",
       " 'INCOME_AMT_100000-499999',\n",
       " 'INCOME_AMT_10M-50M',\n",
       " 'INCOME_AMT_1M-5M',\n",
       " 'INCOME_AMT_25000-99999',\n",
       " 'INCOME_AMT_50M+',\n",
       " 'INCOME_AMT_5M-10M',\n",
       " 'SPECIAL_CONSIDERATIONS_N',\n",
       " 'SPECIAL_CONSIDERATIONS_Y']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge one-hot encoded features and drop the originals\n",
    "df = df.merge(encode_df, left_index=True, right_index=True)\n",
    "df = df.drop(df_cat,1)\n",
    "display(df.head())\n",
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data: Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "# Also drop columns for X dataframe:\n",
    "# special considerations_N (b/c already a special_considerations_Y)\n",
    "# user_case_other & affiliation_other (b/c each only makes up 3-4 rows of data)\n",
    "y = df['IS_SUCCESSFUL'].values\n",
    "X = df.drop(['IS_SUCCESSFUL','SPECIAL_CONSIDERATIONS_N','USE_CASE_Other','AFFILIATION_Other'], 1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of feature variable columns\n",
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 3s 98us/sample - loss: 0.5841 - accuracy: 0.7138\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5726 - accuracy: 0.7229\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5700 - accuracy: 0.7244\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5676 - accuracy: 0.7249\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5646 - accuracy: 0.7263\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5613 - accuracy: 0.7274\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5578 - accuracy: 0.7301\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5550 - accuracy: 0.7289\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5525 - accuracy: 0.7297\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5506 - accuracy: 0.7306\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5490 - accuracy: 0.7315\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5482 - accuracy: 0.7317\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5467 - accuracy: 0.7324\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5466 - accuracy: 0.7329\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5456 - accuracy: 0.7314\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5449 - accuracy: 0.7324\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5448 - accuracy: 0.7331\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5443 - accuracy: 0.7318\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5436 - accuracy: 0.7332\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5432 - accuracy: 0.7333\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5428 - accuracy: 0.7341\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5425 - accuracy: 0.7334\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5423 - accuracy: 0.7338\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5418 - accuracy: 0.7338\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5412 - accuracy: 0.7346\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5414 - accuracy: 0.7346\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5412 - accuracy: 0.7342\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5411 - accuracy: 0.7335\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5409 - accuracy: 0.7349\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5403 - accuracy: 0.7354\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5401 - accuracy: 0.7350\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5403 - accuracy: 0.7347\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5395 - accuracy: 0.7358\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 2s 87us/sample - loss: 0.5402 - accuracy: 0.7349\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 2s 95us/sample - loss: 0.5396 - accuracy: 0.7339\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 2s 86us/sample - loss: 0.5391 - accuracy: 0.7361\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 2s 86us/sample - loss: 0.5393 - accuracy: 0.7343\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5386 - accuracy: 0.7355\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5392 - accuracy: 0.7358\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5386 - accuracy: 0.7353\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5385 - accuracy: 0.7353\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.5387 - accuracy: 0.7359\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 2s 87us/sample - loss: 0.5384 - accuracy: 0.7356\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5379 - accuracy: 0.7352\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5377 - accuracy: 0.7369\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5378 - accuracy: 0.7360\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5376 - accuracy: 0.7361\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5377 - accuracy: 0.7355\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5375 - accuracy: 0.7361\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5376 - accuracy: 0.7368\n",
      "8575/1 - 1s - loss: 0.5613 - accuracy: 0.7272\n",
      "Loss: 0.5536097192277714, Accuracy: 0.7272303104400635\n"
     ]
    }
   ],
   "source": [
    "# 44 inputs; sigmoid, sigmoid; 88 neurons (2X input), epoch = 50\n",
    "\n",
    "# Define the basic neural network model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=88, activation=\"sigmoid\", input_dim=44))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 0.5840 - accuracy: 0.7144\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5721 - accuracy: 0.7236\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5692 - accuracy: 0.7246\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5672 - accuracy: 0.7250\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5638 - accuracy: 0.7272\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5609 - accuracy: 0.7293\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5586 - accuracy: 0.7292\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5554 - accuracy: 0.7301\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5537 - accuracy: 0.7306\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5520 - accuracy: 0.7306\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5504 - accuracy: 0.7310\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5493 - accuracy: 0.7308\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5477 - accuracy: 0.7322\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5471 - accuracy: 0.7310\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5464 - accuracy: 0.7327\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5456 - accuracy: 0.7330\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5451 - accuracy: 0.7329\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5445 - accuracy: 0.7322\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5440 - accuracy: 0.7311\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5436 - accuracy: 0.7334\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5436 - accuracy: 0.7341\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5430 - accuracy: 0.7344\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5427 - accuracy: 0.7349\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5424 - accuracy: 0.7318\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5417 - accuracy: 0.7341\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5417 - accuracy: 0.7347\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5420 - accuracy: 0.7338\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5414 - accuracy: 0.7344\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5407 - accuracy: 0.7353\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5409 - accuracy: 0.7348\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5402 - accuracy: 0.7364\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5401 - accuracy: 0.7360\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5397 - accuracy: 0.7355\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5394 - accuracy: 0.7352\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5397 - accuracy: 0.7357\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5394 - accuracy: 0.7352\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5392 - accuracy: 0.7358\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5393 - accuracy: 0.7345\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5386 - accuracy: 0.7366\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5385 - accuracy: 0.7361\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5388 - accuracy: 0.7367\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5380 - accuracy: 0.7371\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5381 - accuracy: 0.7352\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5382 - accuracy: 0.7363\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5381 - accuracy: 0.7368\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5374 - accuracy: 0.7368\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5378 - accuracy: 0.7361\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5375 - accuracy: 0.7361\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5372 - accuracy: 0.7372\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5371 - accuracy: 0.7354\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5374 - accuracy: 0.7364\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5371 - accuracy: 0.7366\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5372 - accuracy: 0.7386\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5370 - accuracy: 0.7369\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5366 - accuracy: 0.7366\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5367 - accuracy: 0.7383\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5366 - accuracy: 0.7363\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5362 - accuracy: 0.7378\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5363 - accuracy: 0.7388\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5362 - accuracy: 0.7371\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5362 - accuracy: 0.7390\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5360 - accuracy: 0.7381\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5361 - accuracy: 0.7379\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5362 - accuracy: 0.7375\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5359 - accuracy: 0.7383\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5358 - accuracy: 0.7379\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5355 - accuracy: 0.7386\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5357 - accuracy: 0.7388\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5353 - accuracy: 0.7386\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5355 - accuracy: 0.7397\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5353 - accuracy: 0.7403\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5354 - accuracy: 0.7388\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5352 - accuracy: 0.7388\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5351 - accuracy: 0.7380\n",
      "Epoch 75/100\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5350 - accuracy: 0.7383\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5353 - accuracy: 0.7395\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5347 - accuracy: 0.7399\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5343 - accuracy: 0.7381\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5347 - accuracy: 0.7391\n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5348 - accuracy: 0.7381\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5343 - accuracy: 0.7390\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5343 - accuracy: 0.7409\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5345 - accuracy: 0.7396\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5342 - accuracy: 0.7391\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5340 - accuracy: 0.7390\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5343 - accuracy: 0.7397\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5341 - accuracy: 0.7390\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5344 - accuracy: 0.7390\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5340 - accuracy: 0.7404\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5339 - accuracy: 0.7397\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5338 - accuracy: 0.7399\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5339 - accuracy: 0.7392\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5341 - accuracy: 0.7388\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5336 - accuracy: 0.7396\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5340 - accuracy: 0.7388\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5340 - accuracy: 0.7382\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5338 - accuracy: 0.7398\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 0.5338 - accuracy: 0.7407\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5337 - accuracy: 0.7394\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5337 - accuracy: 0.7393\n",
      "8575/1 - 1s - loss: 0.5537 - accuracy: 0.7291\n",
      "Loss: 0.5531499985147148, Accuracy: 0.7290962338447571\n"
     ]
    }
   ],
   "source": [
    "# 44 inputs; sigmoid, sigmoid; 88 neurons (2X input), epoch = 100\n",
    "\n",
    "# Define the basic neural network model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=88, activation=\"sigmoid\", input_dim=44))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 3s 104us/sample - loss: 0.5847 - accuracy: 0.7141\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5738 - accuracy: 0.7222\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5720 - accuracy: 0.7225\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5694 - accuracy: 0.7237\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5669 - accuracy: 0.7252\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5638 - accuracy: 0.7264\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5607 - accuracy: 0.7283\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5581 - accuracy: 0.7292\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5551 - accuracy: 0.7294\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5532 - accuracy: 0.7315\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5513 - accuracy: 0.7313\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5503 - accuracy: 0.7317\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5487 - accuracy: 0.7308\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5485 - accuracy: 0.7310\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5467 - accuracy: 0.7338\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5460 - accuracy: 0.7326\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5461 - accuracy: 0.7329\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5450 - accuracy: 0.7323\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5444 - accuracy: 0.7325\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5443 - accuracy: 0.7330\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5439 - accuracy: 0.7332\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5435 - accuracy: 0.7342\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5427 - accuracy: 0.7353\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5428 - accuracy: 0.7347\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5426 - accuracy: 0.7345\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5419 - accuracy: 0.7355\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5419 - accuracy: 0.7335\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5415 - accuracy: 0.7346\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5411 - accuracy: 0.7345\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5409 - accuracy: 0.7343\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5405 - accuracy: 0.7345\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5403 - accuracy: 0.7348\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5399 - accuracy: 0.7367\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5400 - accuracy: 0.7371\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5397 - accuracy: 0.7348\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5395 - accuracy: 0.7342\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5392 - accuracy: 0.7352\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5390 - accuracy: 0.7365\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5393 - accuracy: 0.7365\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5389 - accuracy: 0.7360\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5384 - accuracy: 0.7374\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5385 - accuracy: 0.7352\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5386 - accuracy: 0.7372\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5386 - accuracy: 0.7360\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5383 - accuracy: 0.7346\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5378 - accuracy: 0.7373\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5378 - accuracy: 0.7376\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5374 - accuracy: 0.7358\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5373 - accuracy: 0.7370\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5379 - accuracy: 0.7363\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5374 - accuracy: 0.7367\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5373 - accuracy: 0.7378\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5370 - accuracy: 0.7371\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5370 - accuracy: 0.7350\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5367 - accuracy: 0.7365\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5370 - accuracy: 0.7386\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5368 - accuracy: 0.7379\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5366 - accuracy: 0.7377\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5369 - accuracy: 0.7376\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5363 - accuracy: 0.7372\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5365 - accuracy: 0.7374\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5361 - accuracy: 0.7375\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5358 - accuracy: 0.7374\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5364 - accuracy: 0.7360\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5358 - accuracy: 0.7383\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5363 - accuracy: 0.7383\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5358 - accuracy: 0.7385\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5357 - accuracy: 0.7384\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.5362 - accuracy: 0.7383s - loss: 0.5375 - accu\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 3s 103us/sample - loss: 0.5352 - accuracy: 0.7388\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.5358 - accuracy: 0.7379\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 3s 124us/sample - loss: 0.5353 - accuracy: 0.7389\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5351 - accuracy: 0.7374\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 0.5358 - accuracy: 0.7383\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25724/25724 [==============================] - 2s 97us/sample - loss: 0.5355 - accuracy: 0.7381\n",
      "Epoch 76/100\n",
      "25724/25724 [==============================] - 3s 103us/sample - loss: 0.5350 - accuracy: 0.7390\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 0.5350 - accuracy: 0.7381\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.5347 - accuracy: 0.7389\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5354 - accuracy: 0.7377\n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5346 - accuracy: 0.7386\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 0.5345 - accuracy: 0.7385\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5347 - accuracy: 0.7394\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5346 - accuracy: 0.7392\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5351 - accuracy: 0.7387\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5347 - accuracy: 0.7381\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 2s 88us/sample - loss: 0.5344 - accuracy: 0.7389\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5345 - accuracy: 0.7391\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5347 - accuracy: 0.7388\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5343 - accuracy: 0.7382\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5343 - accuracy: 0.7389\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5343 - accuracy: 0.7379\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5341 - accuracy: 0.7383\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5342 - accuracy: 0.7391\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5341 - accuracy: 0.7392\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5341 - accuracy: 0.7390\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5344 - accuracy: 0.7392\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5337 - accuracy: 0.7392\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5336 - accuracy: 0.7390\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 2s 86us/sample - loss: 0.5342 - accuracy: 0.7375\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5339 - accuracy: 0.7383\n",
      "8575/1 - 1s - loss: 0.5691 - accuracy: 0.7282\n",
      "Loss: 0.5535318130862956, Accuracy: 0.7281632423400879\n"
     ]
    }
   ],
   "source": [
    "# 44 inputs; sigmoid, sigmoid; 132 neurons (3X input), epoch = 100\n",
    "\n",
    "# Define the basic neural network model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=132, activation=\"sigmoid\", input_dim=44))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 0.5718 - accuracy: 0.7187\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5561 - accuracy: 0.7285\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.5530 - accuracy: 0.7284\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5512 - accuracy: 0.7299\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5493 - accuracy: 0.7313\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5487 - accuracy: 0.7316\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5481 - accuracy: 0.7333\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5475 - accuracy: 0.7329\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5462 - accuracy: 0.7325\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5461 - accuracy: 0.7320\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5455 - accuracy: 0.7322\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5451 - accuracy: 0.7325\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5450 - accuracy: 0.7320\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5444 - accuracy: 0.7331\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5443 - accuracy: 0.7349\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5443 - accuracy: 0.7325\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5438 - accuracy: 0.7322\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5434 - accuracy: 0.7327\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5430 - accuracy: 0.7337\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5430 - accuracy: 0.7342\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5432 - accuracy: 0.7323\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5429 - accuracy: 0.7335\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5423 - accuracy: 0.7320\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5425 - accuracy: 0.7334\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5419 - accuracy: 0.7341\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5419 - accuracy: 0.7336\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5416 - accuracy: 0.7333\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5420 - accuracy: 0.7341\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5417 - accuracy: 0.7345\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5411 - accuracy: 0.7348\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5412 - accuracy: 0.7345\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5411 - accuracy: 0.7347\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5409 - accuracy: 0.7336\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5404 - accuracy: 0.7350\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5406 - accuracy: 0.7346\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5400 - accuracy: 0.7361\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5402 - accuracy: 0.7354\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5402 - accuracy: 0.7356\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5396 - accuracy: 0.7342\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5398 - accuracy: 0.7354\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5399 - accuracy: 0.7346\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5396 - accuracy: 0.7363\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5396 - accuracy: 0.7355\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5395 - accuracy: 0.7367\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5394 - accuracy: 0.7341\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5394 - accuracy: 0.7360\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5384 - accuracy: 0.7356\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5387 - accuracy: 0.7356\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5388 - accuracy: 0.7337\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5394 - accuracy: 0.7362\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5386 - accuracy: 0.7359\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5391 - accuracy: 0.7371\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5390 - accuracy: 0.7346\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5384 - accuracy: 0.7371\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5384 - accuracy: 0.7352\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5388 - accuracy: 0.7361\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5381 - accuracy: 0.7360\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5385 - accuracy: 0.7344\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5382 - accuracy: 0.7361\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5379 - accuracy: 0.7365\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5384 - accuracy: 0.7362\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5373 - accuracy: 0.7355\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5376 - accuracy: 0.7373\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5378 - accuracy: 0.7370\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5377 - accuracy: 0.7367\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5373 - accuracy: 0.7350\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5378 - accuracy: 0.7358\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5371 - accuracy: 0.7374\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5374 - accuracy: 0.7357\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5374 - accuracy: 0.7360\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5373 - accuracy: 0.7371\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5377 - accuracy: 0.7366\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5375 - accuracy: 0.7363\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5371 - accuracy: 0.7356\n",
      "Epoch 75/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5377 - accuracy: 0.7362\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5370 - accuracy: 0.7374\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5373 - accuracy: 0.7386\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5365 - accuracy: 0.7383\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5366 - accuracy: 0.7371\n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5369 - accuracy: 0.7364\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5368 - accuracy: 0.7378\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5364 - accuracy: 0.7365\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5364 - accuracy: 0.7376\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5365 - accuracy: 0.7383\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5362 - accuracy: 0.7370\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5367 - accuracy: 0.7367\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5362 - accuracy: 0.7392\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5364 - accuracy: 0.7364\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5366 - accuracy: 0.7383\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5360 - accuracy: 0.7365\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5361 - accuracy: 0.7371\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5359 - accuracy: 0.7392\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5354 - accuracy: 0.7380\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5356 - accuracy: 0.7381\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5359 - accuracy: 0.7386\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5357 - accuracy: 0.7381\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5359 - accuracy: 0.7392\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5354 - accuracy: 0.7380\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5360 - accuracy: 0.7378\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5357 - accuracy: 0.7381\n",
      "8575/1 - 1s - loss: 0.5479 - accuracy: 0.7297\n",
      "Loss: 0.5547587489942768, Accuracy: 0.72967928647995\n"
     ]
    }
   ],
   "source": [
    "# 44 inputs; relu, sigmoid; 132 neurons (3X input), epoch = 100\n",
    "\n",
    "# Define the basic neural network model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=132, activation=\"relu\", input_dim=44))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 10)                450       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 511\n",
      "Trainable params: 511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# relu, relu, sigmoid; 10, 5 neurons; epoch = 100\n",
    "\n",
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 10\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 6444.5455 - accuracy: 0.4893\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6978 - accuracy: 0.5324\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6924 - accuracy: 0.5324\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6912 - accuracy: 0.5324\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 2s 64us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 2s 63us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 2s 63us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6910 - accuracy: 0.5324\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 2s 63us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 2s 61us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 75/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 1s 51us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 1s 51us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 1s 51us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "8575/1 - 0s - loss: 0.6856 - accuracy: 0.5324\n",
      "Loss: 0.6910555050185401, Accuracy: 0.5323615074157715\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 24)                1080      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# relu, relu, sigmoid; 24, 12 neurons; epoch = 100\n",
    "\n",
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 24\n",
    "hidden_nodes_layer2 = 12\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 26665.5284 - accuracy: 0.5038\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 40197.9673 - accuracy: 0.5009\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 13782.8913 - accuracy: 0.5029\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 15837.3642 - accuracy: 0.5044\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 21562.0841 - accuracy: 0.5055\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 5974.6958 - accuracy: 0.5204\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 9556.5341 - accuracy: 0.5209\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 11484.5966 - accuracy: 0.4906\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 12903.1695 - accuracy: 0.5080\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 5880.2276 - accuracy: 0.5286\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 5492.3118 - accuracy: 0.5088\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 4457.2556 - accuracy: 0.5166\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 11120.8548 - accuracy: 0.5245\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 17664.3253 - accuracy: 0.5172s - loss: 23387.981\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 15695.3896 - accuracy: 0.5068\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 3059.0673 - accuracy: 0.5250\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 7911.5744 - accuracy: 0.5079\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 8826.7359 - accuracy: 0.5098\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 4357.0017 - accuracy: 0.5381\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 5308.3860 - accuracy: 0.5210\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 2926.7057 - accuracy: 0.5282\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 174.8766 - accuracy: 0.5637\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.9574 - accuracy: 0.5324\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.7847 - accuracy: 0.5324\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.7052 - accuracy: 0.5324\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 2s 61us/sample - loss: 0.6747 - accuracy: 0.5516\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6477 - accuracy: 0.6354\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.6371 - accuracy: 0.6417\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6316 - accuracy: 0.6272\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6260 - accuracy: 0.6271\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6225 - accuracy: 0.6275\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6304 - accuracy: 0.6280\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6405 - accuracy: 0.6279\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6399 - accuracy: 0.6278\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6397 - accuracy: 0.6281\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6396 - accuracy: 0.6280\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6396 - accuracy: 0.6282\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6396 - accuracy: 0.6284\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6404 - accuracy: 0.6278\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6399 - accuracy: 0.6288\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6409 - accuracy: 0.6282\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6413 - accuracy: 0.6281\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6450 - accuracy: 0.6253\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6496 - accuracy: 0.6112\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6917 - accuracy: 0.5060\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 76/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.6910 - accuracy: 0.5324\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "8575/1 - 0s - loss: 0.6860 - accuracy: 0.5324\n",
      "Loss: 0.6910526782152604, Accuracy: 0.5323615074157715\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 24)                1080      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# tanh, tanh, sigmoid; 24, 12 neurons; epoch = 100\n",
    "\n",
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 24\n",
    "hidden_nodes_layer2 = 12\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.6925 - accuracy: 0.5238\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6919 - accuracy: 0.5281\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.6918 - accuracy: 0.5265\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6916 - accuracy: 0.5314\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.6914 - accuracy: 0.5310\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 2s 61us/sample - loss: 0.6915 - accuracy: 0.5324\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.6915 - accuracy: 0.5313\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6914 - accuracy: 0.5309\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6912 - accuracy: 0.5315\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6912 - accuracy: 0.5324\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6912 - accuracy: 0.5324\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6912 - accuracy: 0.5324\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6915 - accuracy: 0.5324\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6913 - accuracy: 0.5307\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6912 - accuracy: 0.5324s - loss: 0.6\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6912 - accuracy: 0.5324\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6913 - accuracy: 0.5315\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6912 - accuracy: 0.5324\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6912 - accuracy: 0.5318\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6912 - accuracy: 0.5324\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 76/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.6912 - accuracy: 0.5324\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 2s 58us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6912 - accuracy: 0.5324\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6913 - accuracy: 0.5306\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6912 - accuracy: 0.5324\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.6912 - accuracy: 0.5324\n",
      "8575/1 - 0s - loss: 0.6846 - accuracy: 0.5324\n",
      "Loss: 0.6912033161338494, Accuracy: 0.5323615074157715\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
